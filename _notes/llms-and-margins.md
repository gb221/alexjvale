---
layout: note
title: What LLMs means for EBITDA margins
date: 2025-01-04
---
This is a follow-on from a note on [how adopting SaaS impacted industry’s EBITDA margins](/n/saas-and-margins).

-

It’s abundantly clear that LLMs are capable of performing white-collar work.

Sure, there are areas where they excel and areas where they need a little more nudging - but the statement that “AI can perform average white-collar work” is, at this point in time, essentially true.

And that’s an important factor - *at this point in time*.

Content creation, legal services, programming, accounting, education, data analysis, customer service, and more are all currently undergoing significant transformation.

There’s debate as to how much better the foundation models can get but it’s almost certain that:

- Models with larger parameters will be released
- Post-training techniques will continue to improve
- Hardware will become more optimised (and available at greater scale)
- And costs will continue to drop

It all points towards a monumental upheaval in how white-collar work will be performed.

The game is changing under our feet; so what does that mean for EBITDA margins?

-

There are two important tracks to consider. AI-enablement and AI-replacement.

AI-enablement is what most people are experiencing now. You're probably using it already: asking ChatGPT to help debug your code, or outline an essay, or explain a complex topic. It's like having a really smart colleague who's always available. You're still doing the work, but you're doing it with superpowers.

AI-replacement is different. Instead of augmenting human work, it eliminates it entirely. Imagine a customer service email arriving at a company. Instead of going to a human agent, an AI reads it, understands it, accesses the relevant systems, and solves the problem. No humans involved at any step. This isn't theoretical - it's happening now, just not as visibly as enablement.

The reason this distinction matters is that these two tracks have fundamentally different implications. One makes humans more powerful. The other makes them unnecessary.

Let’s break them down.

-

In 2023 BCG and the Harvard Business School released [a research paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4573321#). It looked at how their consultants performed on a series of tests - some were given access to GPT-4, and some weren’t. The results were decidedly clear: access to AI made the consultants >20% better at their jobs.

![bcg-study-quality-curves.png](/resources/images/bcg-study-quality-curves.png)
*'GPT + Overview' were a cohort who were given prompt engineering tutorials beforehand*

BCG’s entire business model revolves around selling their consultants’ time and their entire moat revolves around their association with quality. Now, for a tiny fraction of their annual salaries, their consultants are provably 20% better.

So will BCG charge 20% more? Will they hire 20% fewer people? Probably not.

I actually think BCG will soon no longer exist.

One of the paper’s starkest findings is revealed when they divided how well the worst consultants, and the best consultants, performed with and without AI.

![bcg-study-task-skill-delta.png](/resources/images/bcg-study-task-skill-delta.png)

The less skilled a consultant was at a task initially, the more AI improved their output. The best got better too, but not by as much.

In other words, AI made an incredible dent in levelling the playing field.

This is a big deal.

For centuries, we've organised work around the assumption that some people are just dramatically better at certain tasks than others. That's why consulting firms can charge $750k/year for a fresh graduate from Harvard. They're not just selling the person's intelligence - they're selling the scarcity of that intelligence.

But what happens when that scarcity disappears? What happens when a $20/month subscription can upgrade an $80k/year junior to produce work that rivals that Harvard grad?

*Intelligence will become a commodity.*

And when something scarce becomes abundant, the price collapses.[^1]

-

The most remarkable thing about AI-enabled work is how accessible it is. All you need is an internet connection, the ability to provide context, and the cost is essentially meaningless. Everything points towards it spreading like wildfire through the white-collar labour market.[^2]

The trend will only accelerate too. As it becomes clear how much more effective an enabled worker is they’ll be increasing pressure to adapt. Either catch the wave or be left behind for good.

So if you assume AI-enablement becomes as universal as having a computer (and all signs point that way), you can start to envision the impact on industry.

But what if *the human is removed entirely?* The economics become almost absurd.

Take due diligence for example. A team of people might spend weeks combing through documents, cross-referencing data, and building models. That's tens of thousands of dollars in cost. But what happens when an AI can do it, end-to-end, matching the quality for a fraction of the cost and time?

The really crazy part is that once a workflow gets automated, the cost approaches zero at scale. Why would anyone pay human-based prices once that happens?

-

So what happens to EBITDA margins when workers gains a superpower and huge swathes of work cost nothing?

First, they’ll be a massive productivity arbitrage. Companies that move quickly can either:

1. Maintain their current headcount but dramatically increase output
2. Maintain current output with far fewer people

Either way, their unit economics suddenly look much better than their competitors'.

But this [advantage has historically been temporary](/n/innovations-and-margins). As AI-enabled work spreads, it will become the new baseline. When everyone has a superpower, it's not really a superpower anymore - it's table stakes.

This leads to four likely scenarios:

1. **EBITDA margin expansion.** Companies capture the productivity gains as profit, doing the same work with fewer people or more work with the same people
2. **Price compression.** Competition forces companies to pass savings to customers, similar to what happened with automated manufacturing
3. **Quality explosion.** The bar for acceptable work rises dramatically as enhanced output becomes the norm
4. **The death of certain industries.** Industries that primarily sell human time for standardisable knowledge work will face existential pressure[^3]

Companies that move first will enjoy temporary margin expansion. Then competitive pressure will most likely force price reductions. Meanwhile, the standard for what constitutes acceptable work will steadily rise.

Because the expansions and compressions will be so drastic there's much to be gained from moving first.

A company that aggressively adopts AI-enabled work could potentially cut their white-collar labour costs by 30-50% while maintaining output. Those margins aren't just going to look good on paper - they'll create real strategic options.

They could:

- Undercut competitors on price and grow marketshare
- Reinvest the savings into R&D and develop market-defining products
- Acquire struggling competitors who moved too slowly

The question isn't whether this transformation happens, but who captures the value during the transition.

Right now, that question is wide open.

---

[^1]: There are many, many, implications here. What happens to higher education when a degree no longer makes as much of a difference? Will companies begin screening for AI-usage abilities vs. intellectual proficiency? How will salaries adjust considering the psychological barrier to them going down?

[^2]: A [2023 survey of 2,200 American workers](https://www.business.com/technology/chatgpt-usage-workplace-study/) revealed that 57% had tried ChatGPT and 16% regularly used it in their day-to-day work. Staggeringly, only 1% had never heard of it.

[^3]: This isn't just theoretical. We've seen similar transitions before: travel agents, stock brokers, photo processing, and more didn't just become more efficient - they largely disappeared. The difference now is that AI targets white-collar, high-margin knowledge work that was previously thought to be automation-proof.